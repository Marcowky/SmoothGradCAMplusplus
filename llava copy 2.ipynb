{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置可见的GPU 为 3 和4\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4, 5\"\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必备的包\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import tokenizer_image_token, process_images, get_model_name_from_path, select_best_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型、测试样例设置\n",
    "\n",
    "model_path = '/home/kaiyu/Model/liuhaotian/llava-v1.6-vicuna-7b/'\n",
    "model_base = None\n",
    "question = 'Is there a cat in the image?\\\\nAnswer the question using a single word or phrase.'\n",
    "# question = 'describe the image'\n",
    "# image_file = \"./sample/dogsled.jpg\"\n",
    "image_file = \"./sample/tigercat.jpg\"\n",
    "conv_mode = 'vicuna_v1'\n",
    "temperature = 0\n",
    "top_p = None\n",
    "num_beams = 1\n",
    "\n",
    "# from ImageNet\n",
    "image = Image.open(image_file).convert('RGB')\n",
    "# image = Image.open('./sample/dogsled.jpg')\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*copying from a non-meta parameter.*\")\n",
    "\n",
    "# Model\n",
    "disable_torch_init()\n",
    "model_path = os.path.expanduser(model_path)\n",
    "model_name = get_model_name_from_path(model_path)\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, model_base, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 处理\n",
    "\n",
    "qs = question\n",
    "cur_prompt = qs\n",
    "if model.config.mm_use_im_start_end:\n",
    "    qs = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + qs\n",
    "else:\n",
    "    qs = DEFAULT_IMAGE_TOKEN + '\\n' + qs\n",
    "\n",
    "conv = conv_templates[conv_mode].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
    "\n",
    "image_tensor = process_images([image], image_processor, model.config)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ids in enumerate(input_ids[0]):\n",
    "    if(i == 35):\n",
    "        # print(i + 1 - len(temp_ids[0]), tokenizer.batch_decode([ids], skip_special_tokens=True), end='  ')\n",
    "        continue\n",
    "    print(i + 1 - len(input_ids[0]), tokenizer.batch_decode([ids], skip_special_tokens=True), end='  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理\n",
    "\n",
    "model.train()\n",
    "\n",
    "image_tensor = image_tensor.unsqueeze(0).half().cuda()\n",
    "image_tensor.requires_grad_()\n",
    "\n",
    "output = model(\n",
    "    input_ids=input_ids,\n",
    "    use_cache=False,\n",
    "    images=image_tensor,\n",
    "    image_sizes=[image.size],\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 计算 CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 获取注意力分数并激活梯度跟踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = output.attentions  # 假设out是模型的输出，并且包含注意力权重\n",
    "for attn_layer in attentions:\n",
    "    attn_layer.retain_grad()  # 保留非叶张量的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 预测输出并反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = output.logits\n",
    "label_index = prediction.argmax(dim=-1)  # 获取输出索引，这里假设是argmax作为预测类别\n",
    "prediction_score = prediction[:, -1, label_index[0][-1]]  # 获取对应的得分\n",
    "\n",
    "prediction_score.backward()  # 对得分进行反向传播，生成梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 获取梯度并计算 cam 值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = [attn_layer.grad for attn_layer in attentions]  # 获取所有层的梯度\n",
    "\n",
    "attn_res = []\n",
    "modified_attention = []\n",
    "grad_res = []\n",
    "\n",
    "for attn_layer, grad_layer in zip(attentions, gradient):\n",
    "    attn_single = attn_layer\n",
    "    attn_single = attn_single.mean(dim=1)  # 假设我们合并头部的注意力\n",
    "    # attn_single = F.relu(attn_single)\n",
    "    attn_res.append(attn_single)\n",
    "\n",
    "    if(grad_layer is None):\n",
    "        continue\n",
    "    \n",
    "    # 广播后点乘的shape可能是 [batch_size, num_heads, seq_length, seq_length]\n",
    "    grad_weighted_attn = grad_layer * attn_layer\n",
    "    grad_weighted_attn = grad_weighted_attn.mean(dim=1)  # 假设我们合并头部的注意力\n",
    "    # grad_weighted_attn = F.relu(grad_weighted_attn)\n",
    "    modified_attention.append(grad_weighted_attn)\n",
    "\n",
    "    grad_single = grad_layer\n",
    "    grad_single = grad_single.mean(dim=1)  # 假设我们合并头部的注意力\n",
    "    # grad_single = F.relu(grad_single)\n",
    "    grad_res.append(grad_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modified_attention[0][0][-1, -63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 假设 attn_res, grad_res, modified_attention 已经定义\n",
    "# attn_res = ...\n",
    "# grad_res = ...\n",
    "# modified_attention = ...\n",
    "\n",
    "layer_nums_attention = range(32)  # 0-31\n",
    "layer_nums_grad_cam = range(5)    # 0-4\n",
    "target_tokens = [-1]  # 固定\n",
    "ttypes = ['attention', 'grad', 'cam']\n",
    "\n",
    "# 准备表头\n",
    "headers = []\n",
    "data = []\n",
    "\n",
    "for ttype in ttypes:\n",
    "    if ttype == 'attention':\n",
    "        layer_nums = layer_nums_attention\n",
    "        temp_info = attn_res\n",
    "    elif ttype == 'grad':\n",
    "        layer_nums = layer_nums_grad_cam\n",
    "        temp_info = grad_res\n",
    "    elif ttype == 'cam':\n",
    "        layer_nums = layer_nums_grad_cam\n",
    "        temp_info = modified_attention\n",
    "\n",
    "    for layer_num in layer_nums:\n",
    "        header = f\"{ttype}_{layer_num}\"\n",
    "        headers.append(header)\n",
    "        column_data = []\n",
    "        for target_token in target_tokens:\n",
    "            res = temp_info[layer_num][0][target_token, -63:]\n",
    "            column_data.extend([r.item() for r in res])\n",
    "        data.append(column_data)\n",
    "\n",
    "# 转置数据，使每行对应一个数据点\n",
    "transposed_data = list(zip(*data))\n",
    "\n",
    "# 写入 CSV 文件\n",
    "with open('results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # 写入表头\n",
    "    writer.writerow(headers)\n",
    "    # 写入数据\n",
    "    writer.writerows(transposed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 attn_res, grad_res, modified_attention, image 已经定义\n",
    "# attn_res = ...\n",
    "# grad_res = ...\n",
    "# modified_attention = ...\n",
    "# image = ...\n",
    "\n",
    "target_token = -1\n",
    "\n",
    "ttype = 'attention'\n",
    "# ttype = 'grad'\n",
    "# ttype = 'cam'\n",
    "\n",
    "if ttype == 'attention':\n",
    "    temp_info = attn_res\n",
    "elif ttype == 'grad':\n",
    "    temp_info = grad_res\n",
    "elif ttype == 'cam':\n",
    "    temp_info = modified_attention\n",
    "\n",
    "for layer_num in range(32):\n",
    "    res = temp_info[layer_num][0][target_token, -63:]\n",
    "\n",
    "    visual_cam = temp_info[layer_num][0][target_token, 35:611]\n",
    "\n",
    "    # visual_cam 转为 24 * 24 的矩阵\n",
    "    visual_cam = visual_cam.reshape(24, 24).cpu().detach().float()\n",
    "\n",
    "    # 对 CAM 分数进行拉伸差值\n",
    "    H, W = image.size\n",
    "    cam = F.interpolate(visual_cam.unsqueeze(0).unsqueeze(0), size=(W, H), mode='bilinear', align_corners=False).squeeze()\n",
    "\n",
    "    # 显示原始图像\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # 叠加热力图\n",
    "    plt.imshow(cam, alpha=0.5, cmap='jet')\n",
    "    plt.title(f'Layer {layer_num}')\n",
    "    plt.show()\n",
    "\n",
    "    # 等待1秒\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取对应的 CAM 分数\n",
    "\n",
    "layer_num = 0\n",
    "target_token = -1\n",
    "\n",
    "ttype = 'attention'\n",
    "# ttype = 'grad'\n",
    "# ttype = 'cam'\n",
    "\n",
    "if ttype == 'attention':\n",
    "    temp_info = attn_res\n",
    "elif ttype == 'grad':\n",
    "    temp_info = grad_res\n",
    "elif ttype == 'cam':\n",
    "    temp_info = modified_attention\n",
    "\n",
    "res = temp_info[layer_num][0][target_token, -63:]\n",
    "# for r in res:\n",
    "#     print(r.item())\n",
    "\n",
    "visual_cam = temp_info[layer_num][0][target_token, 35:611]\n",
    "\n",
    "# visial_cam 转为 24 * 24 的矩阵\n",
    "visual_cam = visual_cam.reshape(24, 24).cpu().detach().float()\n",
    "\n",
    "# 对 CAM 分数进行拉伸差值\n",
    "H, W = image.size\n",
    "cam = F.interpolate(visual_cam.unsqueeze(0).unsqueeze(0), size=(W, H), mode='bilinear', align_corners=False).squeeze()\n",
    "\n",
    "# 显示原始图像\n",
    "imshow(image)\n",
    "\n",
    "# 叠加热力图\n",
    "imshow(cam, alpha=0.5, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_ids[0][1])\n",
    "input_ids[0][35]=1\n",
    "for i, ids in enumerate(input_ids[0]):\n",
    "    print(tokenizer.batch_decode([ids], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
